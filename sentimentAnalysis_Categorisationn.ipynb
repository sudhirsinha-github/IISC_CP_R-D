{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b4069666ab34fcaa0725ba756246de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dc6421a9c544c35988ac6857c0a6110",
              "IPY_MODEL_c08ffa30ee6d483fbc01a010293cca5f",
              "IPY_MODEL_c4a34f43ca1c4b6994b48e3f851696c5"
            ],
            "layout": "IPY_MODEL_36bfa0e5fda64f13944f39747fba54a7"
          }
        },
        "2dc6421a9c544c35988ac6857c0a6110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9efca7aa2a74eefaeee3e04bd239d8b",
            "placeholder": "​",
            "style": "IPY_MODEL_5c23ba960b054ed99170f1340662fba0",
            "value": "Map: 100%"
          }
        },
        "c08ffa30ee6d483fbc01a010293cca5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba1e2eb626b44db87b5eeb5357c727b",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e723f3863bb408fa5c806a884fd29c7",
            "value": 32
          }
        },
        "c4a34f43ca1c4b6994b48e3f851696c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddd91e2b46ef406ea2799aecb1151493",
            "placeholder": "​",
            "style": "IPY_MODEL_d4f11b42e7c24fbeb5453594fec856e1",
            "value": " 32/32 [00:00&lt;00:00, 537.64 examples/s]"
          }
        },
        "36bfa0e5fda64f13944f39747fba54a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9efca7aa2a74eefaeee3e04bd239d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c23ba960b054ed99170f1340662fba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ba1e2eb626b44db87b5eeb5357c727b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e723f3863bb408fa5c806a884fd29c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddd91e2b46ef406ea2799aecb1151493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4f11b42e7c24fbeb5453594fec856e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21z6zEn-UmQK",
        "outputId": "a4111ace-55ea-4aca-8c77-47423de40e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis Results:\n",
            "  Text: \"The customer was very satisfied with the resolution.\"\n",
            "  Sentiment: POSITIVE (Score: 0.9983)\n",
            "\n",
            "  Text: \"I had a terrible experience and the issue was not fixed.\"\n",
            "  Sentiment: NEGATIVE (Score: 0.9997)\n",
            "\n",
            "  Text: \"The agent was polite but couldn't help me resolve the problem.\"\n",
            "  Sentiment: NEGATIVE (Score: 0.9364)\n",
            "\n",
            "  Text: \"This is a neutral statement.\"\n",
            "  Sentiment: NEGATIVE (Score: 0.8372)\n",
            "\n",
            "  Text: \"Everything worked perfectly,except my last order took more than expected time but eggs were spoiled. I expect quickly delivery.... thank you!\"\n",
            "  Sentiment: NEGATIVE (Score: 0.9307)\n",
            "\n",
            "Single Text Sentiment: POSITIVE (Score: 0.9999)\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 1. Load the sentiment-analysis pipeline\n",
        "# This will automatically download and load the 'distilbert-base-uncased-finetuned-sst-2-english' model\n",
        "# along with its tokenizer.\n",
        "\n",
        "# 2. Prepare your text data (call/conversation snippets)\n",
        "texts_to_analyze = [\n",
        "    \"The customer was very satisfied with the resolution.\",\n",
        "    \"I had a terrible experience and the issue was not fixed.\",\n",
        "    \"The agent was polite but couldn't help me resolve the problem.\",\n",
        "    \"This is a neutral statement.\",\n",
        "    \"Everything worked perfectly,except my last order took more than expected time but eggs were spoiled. I expect quickly delivery.... thank you!\",\n",
        "]\n",
        "\n",
        "# 3. Perform sentiment analysis\n",
        "results = sentiment_pipeline(texts_to_analyze)\n",
        "\n",
        "# 4. Print the results\n",
        "print(\"Sentiment Analysis Results:\")\n",
        "for i, text in enumerate(texts_to_analyze):\n",
        "    label = results[i]['label']\n",
        "    score = results[i]['score']\n",
        "    print(f\"  Text: \\\"{text}\\\"\")\n",
        "    print(f\"  Sentiment: {label} (Score: {score:.4f})\\n\")\n",
        "\n",
        "# Example for a single text\n",
        "single_text = \"This product is absolutely amazing and exceeded my expectations!\"\n",
        "single_result = sentiment_pipeline(single_text)\n",
        "print(f\"Single Text Sentiment: {single_result[0]['label']} (Score: {single_result[0]['score']:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "collapsed": true,
        "id": "patK_Lz9XCaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ distilbert-base-uncased is a base language model: trained for understanding language, not for specific tasks like sentiment analysis.\n",
        "#It is not fine-tuned for sentiment analysis by default, so you'll need to fine-tune it yourself, or manually load a classifier head on top and use a fine-tuned checkpoint."
      ],
      "metadata": {
        "id": "mTxoNbY5Wkn_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#🧠 1. Topic Modeling (Unsupervised)\n",
        "#✅ Best for:\n",
        "#Exploring unknown topics in conversation data\n",
        "#Grouping conversations by theme without labels\n",
        "#BERTopic (modern, works well on short texts like chat)\n",
        "# BERTopic uses embeddings (from Sentence-BERT or DistilBERT) + clustering to find interpretable topics.\n",
        "\n",
        "\n",
        "!pip install bertopic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Jig1fiUsYsNa",
        "outputId": "d37f8fba-9a5e-48bb-a06a-38f0e7af04ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertopic\n",
            "  Downloading bertopic-0.17.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting hdbscan>=0.8.29 (from bertopic)\n",
            "  Downloading hdbscan-0.8.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.6.1)\n",
            "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\n",
            "Collecting umap-learn>=0.5.0 (from bertopic)\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (25.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.6.0+cpu)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.14.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.61.2)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.5.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (1.1.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.44.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.6)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.4.26)\n",
            "Downloading bertopic-0.17.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hdbscan-0.8.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n",
            "Successfully installed bertopic-0.17.0 hdbscan-0.8.40 pynndescent-0.5.13 sentence-transformers-4.1.0 umap-learn-0.5.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Topic Modeling (Unsupervised)\n",
        "\n",
        "from bertopic import BERTopic\n",
        "import umap\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "\n",
        "# Example: small set of airline chat snippets\n",
        "conversations = [\n",
        "    \"I need to reset my account password\",\n",
        "    \"I was charged twice for my ticket\",\n",
        "    \"Please call me back about my delayed flight\",\n",
        "    \"How do I apply for a refund?\",\n",
        "    \"Can I change my payment method?\",\n",
        "    \"I want to update my contact number\",\n",
        "    \"When will my refund be processed?\",\n",
        "    \"Schedule a callback for tomorrow\",\n",
        "]\n",
        "\n",
        "# Custom UMAP and KMeans for small dataset\n",
        "umap_model = umap.UMAP(n_neighbors=3, n_components=2, metric='cosine', random_state=42)\n",
        "kmeans_model = KMeans(n_clusters=4, random_state=42)\n",
        "\n",
        "# Fit BERTopic model\n",
        "topic_model = BERTopic(umap_model=umap_model, hdbscan_model=kmeans_model)\n",
        "topics, probs = topic_model.fit_transform(conversations)\n",
        "\n",
        "# Get topic info as a DataFrame\n",
        "df_topics = topic_model.get_topic_info()\n",
        "\n",
        "# Generate topic names from top 3 keywords\n",
        "df_topics[\"Topic_Name\"] = df_topics[\"Representation\"].apply(lambda x: \"_\".join(x[:3]))\n",
        "\n",
        "# Display with readable topic names\n",
        "print(df_topics[[\"Topic\", \"Count\", \"Topic_Name\", \"Representative_Docs\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFj7SDSQZSuT",
        "outputId": "fbd81f3e-f067-4709-b1c7-d06d22f61f81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Topic  Count           Topic_Name  \\\n",
            "0      0      3  for_tomorrow_ticket   \n",
            "1      1      2   to_password_update   \n",
            "2      2      2   how_method_payment   \n",
            "3      3      1  when_will_processed   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  [Schedule a callback for tomorrow, I was charg...  \n",
            "1  [I want to update my contact number, I need to...  \n",
            "2  [How do I apply for a refund?, Can I change my...  \n",
            "3                [When will my refund be processed?]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n",
        "# !pip install --upgrade transformers\n",
        "# !pip install --upgrade datasets transformers\n",
        "!pip install \"numpy<2.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "collapsed": true,
        "id": "pkmYdf7ue9Ut",
        "outputId": "0d257206-66ab-478f-c04d-ce0e24aaa914"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ee64d69af4c0413daa4fa95cc83892c3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
        "print(\"Current device:\", torch.cuda.current_device())\n",
        "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()) if torch.cuda.is_available() else \"No GPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UddEqrjjhGQ2",
        "outputId": "71a1b2db-2227-40bc-8aae-e667a4b602bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Number of GPUs: 1\n",
            "Current device: 0\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments, pipeline\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import numpy as np # It's good practice to import numpy\n",
        "\n",
        "# --- 1. Data Preparation ---\n",
        "data = [\n",
        "    (\"I need to reset my account password\", \"account\"),\n",
        "    (\"I forgot my login credentials\", \"account\"),\n",
        "    (\"Can you help me update my email address?\", \"account\"),\n",
        "    (\"I want to change my account phone number\", \"account\"),\n",
        "    (\"Unable to access my profile\", \"account\"),\n",
        "    (\"My account is locked after multiple attempts\", \"account\"),\n",
        "    (\"Can I delete my account permanently?\", \"account\"),\n",
        "    (\"How do I link my frequent flyer number?\", \"account\"),\n",
        "    (\"How do I apply for a refund?\", \"refund\"),\n",
        "    (\"When will I get my money back?\", \"refund\"),\n",
        "    (\"The flight was cancelled, I need a refund\", \"refund\"),\n",
        "    (\"I haven’t received the refund yet\", \"refund\"),\n",
        "    (\"Can I get a refund for my missed flight?\", \"refund\"),\n",
        "    (\"What is the refund policy for international tickets?\", \"refund\"),\n",
        "    (\"I was promised a refund but it hasn’t arrived\", \"refund\"),\n",
        "    (\"Is there a cancellation fee if I want a refund?\", \"refund\"),\n",
        "    (\"Can I change my payment method?\", \"payment\"),\n",
        "    (\"The transaction failed but money was deducted\", \"payment\"),\n",
        "    (\"How do I add a new credit card?\", \"payment\"),\n",
        "    (\"Is EMI available for ticket bookings?\", \"payment\"),\n",
        "    (\"I was charged twice for one booking\", \"payment\"),\n",
        "    (\"Do you support PayPal payments?\", \"payment\"),\n",
        "    (\"Can I pay later for my ticket?\", \"payment\"),\n",
        "    (\"I need a payment receipt for reimbursement\", \"payment\"),\n",
        "    (\"Please call me back later\", \"callback\"),\n",
        "    (\"I missed your call, please try again\", \"callback\"),\n",
        "    (\"Can you schedule a callback at 5 PM?\", \"callback\"),\n",
        "    (\"I need a call from a supervisor\", \"callback\"),\n",
        "    (\"Is it possible to get a callback for support?\", \"callback\"),\n",
        "    (\"Call me after 2 hours\", \"callback\"),\n",
        "    (\"I requested a callback but no one called\", \"callback\"),\n",
        "    (\"How do I request a callback online?\", \"callback\")\n",
        "]\n",
        "\n",
        "texts, labels = zip(*data)\n",
        "unique_labels = sorted(list(set(labels)))\n",
        "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "encoded_labels = [label2id[label] for label in labels]\n",
        "\n",
        "# --- 2. Tokenizer ---\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# --- 3. Dataset ---\n",
        "dataset_dict = {\n",
        "    \"text\": list(texts),\n",
        "    \"label\": encoded_labels\n",
        "}\n",
        "dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "print(\"Tokenizing dataset...\")\n",
        "dataset = dataset.map(tokenize_function, batched=True)\n",
        "dataset = dataset.remove_columns([\"text\"])\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# --- 4. Model ---\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=len(label2id),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)\n",
        "\n",
        "# --- 5. Training ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./flight_chat_classifier\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=4,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=[]  # disables W&B integration\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "trainer.train()\n",
        "print(\"--- Training Complete ---\")\n",
        "\n",
        "# --- 6. Inference ---\n",
        "print(\"\\n--- Performing Inference ---\")\n",
        "# Use the trained model directly from the Trainer object or load from the output directory\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "# --- 7. Test Predictions ---\n",
        "test_inputs = [\n",
        "    \"I need a refund for my flight\",\n",
        "    \"I missed my password\",\n",
        "    \"I have not got reverse payment for my cancell\",\n",
        "    \"Can you call me back tomorrow morning?\",\n",
        "    \"I want to know my account balance\"\n",
        "]\n",
        "\n",
        "for text in test_inputs:\n",
        "    print(f\"\\nInput: {text}\")\n",
        "    prediction = classifier(text)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775,
          "referenced_widgets": [
            "3b4069666ab34fcaa0725ba756246de3",
            "2dc6421a9c544c35988ac6857c0a6110",
            "c08ffa30ee6d483fbc01a010293cca5f",
            "c4a34f43ca1c4b6994b48e3f851696c5",
            "36bfa0e5fda64f13944f39747fba54a7",
            "f9efca7aa2a74eefaeee3e04bd239d8b",
            "5c23ba960b054ed99170f1340662fba0",
            "8ba1e2eb626b44db87b5eeb5357c727b",
            "6e723f3863bb408fa5c806a884fd29c7",
            "ddd91e2b46ef406ea2799aecb1151493",
            "d4f11b42e7c24fbeb5453594fec856e1"
          ]
        },
        "id": "6uPKiWXwd46z",
        "outputId": "48a8307a-aed1-4b5f-cfc7-d09aa199deeb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b4069666ab34fcaa0725ba756246de3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Starting Model Training ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:10, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.359400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.159900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.885600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Complete ---\n",
            "\n",
            "--- Performing Inference ---\n",
            "\n",
            "Input: I need a refund for my flight\n",
            "Prediction: [{'label': 'refund', 'score': 0.4685707092285156}]\n",
            "\n",
            "Input: I missed my password\n",
            "Prediction: [{'label': 'account', 'score': 0.5573247671127319}]\n",
            "\n",
            "Input: I have not got reverse payment for my cancell\n",
            "Prediction: [{'label': 'payment', 'score': 0.36302199959754944}]\n",
            "\n",
            "Input: Can you call me back tomorrow morning?\n",
            "Prediction: [{'label': 'callback', 'score': 0.32531049847602844}]\n",
            "\n",
            "Input: I want to know my account balance\n",
            "Prediction: [{'label': 'account', 'score': 0.5365785360336304}]\n"
          ]
        }
      ]
    }
  ]
}